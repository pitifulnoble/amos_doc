# Flink Watermark

当我们使用 `EventTime` 处理流数据的时候会遇到数据乱序的问题，流处理从数据产生，到流 经是 `Source`，再到具体的算子，中间是有一个过程和时间的。虽然大部分情况下，传输到算 子的数据都是按照数据产生的时间顺序来的，但是也不排除由于网络延迟等原因，导致乱序 的产生，特别是使用 ``Kafka`` 的时候，多个分区之间的数据无法保证有序。
所以在进行 `Window` 计算的时候，我们又不能无限期地等下去，必须要有一个机制来保证一个特定的时间后，必须触发 `Window` 去进行计算了，这个特别的机制就是`Watermark`使用``Watermark+EventTime``处理乱序数据。
Watermark 可以翻译为水位线。

## 单并行度案例

### 1.代码
```scala
package com.imooc.scala.window

import java.text.SimpleDateFormat
import java.time.Duration

import org.apache.flink.api.common.eventtime.{SerializableTimestampAssigner, WatermarkStrategy}
import org.apache.flink.api.java.tuple.Tuple
import org.apache.flink.streaming.api.TimeCharacteristic
import org.apache.flink.streaming.api.scala.StreamExecutionEnvironment
import org.apache.flink.streaming.api.scala.function.WindowFunction
import org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows
import org.apache.flink.streaming.api.windowing.time.Time
import org.apache.flink.streaming.api.windowing.windows.TimeWindow
import org.apache.flink.util.Collector

import scala.collection.mutable.ArrayBuffer
import scala.util.Sorting

/**
 * Watermark+EventTime解决数据乱序问题
 * Created by xuwei
 */
object WatermarkOpScala {
  def main(args: Array[String]): Unit = {
    val env = StreamExecutionEnvironment.getExecutionEnvironment
    //设置使用数据产生的时间：EventTime
    env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)
    //设置全局并行度为1
    env.setParallelism(1)

    //设置自动周期性的产生watermark，默认值为200毫秒
    env.getConfig.setAutoWatermarkInterval(200)


    val text = env.socketTextStream("bigdata04", 9001)
    import org.apache.flink.api.scala._
    //将数据转换为tuple2的形式
    //第一列表示具体的数据，第二列表示是数据产生的时间戳
    val tupStream = text.map(line => {
      val arr = line.split(",")
      (arr(0), arr(1).toLong)
    })

    //分配(提取)时间戳和watermark
    val waterMarkStream = tupStream.assignTimestampsAndWatermarks(WatermarkStrategy.forBoundedOutOfOrderness(Duration.ofSeconds(10)) //最大允许的数据乱序时间 10s
      .withTimestampAssigner(new SerializableTimestampAssigner[Tuple2[String, Long]] {
        val sdf = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss")
        var currentMaxTimstamp = 0L

        //从数据流中抽取时间戳作为EventTime
        override def extractTimestamp(element: (String, Long), recordTimestamp: Long): Long = {
          val timestamp = element._2
          currentMaxTimstamp = Math.max(timestamp, currentMaxTimstamp)
          //计算当前watermark，为了打印出来方便观察数据，没有别的作用，watermark=currentMaxTimstamp-OutOfOrderness
          val currentWatermark = currentMaxTimstamp - 10000L
          //此print语句仅仅是为了在学习阶段观察数据的变化
          println("key:" + element._1 + "," + "eventtime:[" + element._2 + "|" + sdf.format(element._2) + "],currentMaxTimstamp:[" + currentWatermark + "|" + sdf.format(currentMaxTimstamp) + "],watermark:[" + currentWatermark + "|" + sdf.format(currentWatermark) + "]")
          element._2
        }
      })
    )

    waterMarkStream.keyBy(0)
      //按照消息的EventTime分配窗口，和调用TimeWindow效果一样
      .window(TumblingEventTimeWindows.of(Time.seconds(3)))
      //使用全量聚合的方式处理window中的数据
      .apply(new WindowFunction[Tuple2[String,Long],String,Tuple,TimeWindow] {
        override def apply(key: Tuple, window: TimeWindow, input: Iterable[(String, Long)], out: Collector[String]): Unit = {
          val keyStr = key.toString
          //将window中的数据保存到arrBuff中
          val arrBuff = ArrayBuffer[Long]()
          input.foreach(tup=>{
            arrBuff.append(tup._2)
          })
          //将arrBuff转换为arr
          val arr = arrBuff.toArray
          //对arr中的数据进行排序
          Sorting.quickSort(arr)

          val sdf = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss")
          //将目前window内排序后的数据，以及window的开始时间和window的结束时间打印出来，便于观察
          val result = keyStr+","+arr.length+","+sdf.format(arr.head)+","+sdf.format(arr.last)+","+sdf.format(window.getStart)+","+sdf.format(window.getEnd)
          out.collect(result)
        }
      }).print()

    env.execute("WatermarkOpScala")
  }
}
```
```java
package com.xiaomi.infosec.risk.intranet.xms;

import com.xiaomi.infosec.risk.intranet.xms.util.CommonMethod;
import lombok.extern.slf4j.Slf4j;
import org.apache.flink.api.common.eventtime.SerializableTimestampAssigner;
import org.apache.flink.api.common.eventtime.WatermarkStrategy;
import org.apache.flink.api.common.functions.MapFunction;
import org.apache.flink.api.java.functions.KeySelector;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.streaming.api.datastream.DataStreamSource;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.functions.windowing.WindowFunction;
import org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows;
import org.apache.flink.streaming.api.windowing.time.Time;
import org.apache.flink.streaming.api.windowing.windows.TimeWindow;
import org.apache.flink.util.Collector;

import java.time.Duration;
import java.util.ArrayList;
import java.util.List;
import java.util.stream.Collectors;

@Slf4j
public class FlinkWindowTest {
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        //设置全局并行度为1
        env.setParallelism(2);
        DataStreamSource<String> text = env.socketTextStream("localhost", 9001);
        text.map(new MapFunction<String, Tuple2<String, Long>>() {
                    @Override
                    public Tuple2<String, Long> map(String value) throws Exception {
                        String[] split = value.split(",");
                        return Tuple2.of(split[0], Long.parseLong(split[1]));
                    }
                })
                .assignTimestampsAndWatermarks(WatermarkStrategy.<Tuple2<String, Long>>forBoundedOutOfOrderness(Duration.ofSeconds(10))
                        .withTimestampAssigner(new SerializableTimestampAssigner<Tuple2<String, Long>>() {
                            long currentMaxTimestamp = 0L;

                            @Override
                            public long extractTimestamp(Tuple2<String, Long> element, long recordTimestamp) {
                                long timestamp = element.f1;
                                currentMaxTimestamp = Math.max(timestamp, currentMaxTimestamp);
                                long currentWatermark = currentMaxTimestamp - 10000L;
                                log.info("key:{}, eventTime:[{}|{}],currentMaxTimestamp:[{}|{}],watermark:[{}|{}]",
                                        element.f0, element.f1, CommonMethod.formatTimestamp(element.f1),
                                        currentMaxTimestamp, CommonMethod.formatTimestamp(currentMaxTimestamp),
                                        currentWatermark, CommonMethod.formatTimestamp(currentWatermark));
                                return element.f1;
                            }
                        }))
                .keyBy(new KeySelector<Tuple2<String, Long>, String>() {
                    @Override
                    public String getKey(Tuple2<String, Long> value) throws Exception {
                        return value.f0;
                    }
                })
                .window(TumblingEventTimeWindows.of(Time.seconds(3)))
                .apply(new WindowFunction<Tuple2<String, Long>, String, String, TimeWindow>() {
                    @Override
                    public void apply(String key, TimeWindow window, Iterable<Tuple2<String, Long>> input, Collector<String> out) throws Exception {
                        List<Long> arrBuf = new ArrayList<>();
                        for (Tuple2<String, Long> item : input) {
                            arrBuf.add(item.f1);
                        }
                        List<Long> collect = arrBuf.stream().sorted().collect(Collectors.toList());
                        log.info("{}, length: {}, arrHead: {}, arrEnd: {}, windowStart: {}, windowEnd: {}",
                                key, collect.size(), CommonMethod.formatTimestamp(collect.get(0)), CommonMethod.formatTimestamp(collect.get(collect.size() - 1)),
                                CommonMethod.formatTimestamp(window.getStart()), CommonMethod.formatTimestamp(window.getEnd()));
                    }
                });
        env.execute();
    }
}
```

### 2.通过数据跟踪观察 watermak
在这里重点查看 `Watermark` 和 `Timestamp` 的时间，通过数据的输出来确定 `Window` 的触发时机。
首先我们开启 Socket，输入第一条数据。
```sh
[root@bigdata04 soft]# nc -l 9001
0001,1790820682000
```
输出的内容如下
```
key:0001,eventtime:[1790820682000|2026-10-01 10:11:22],currentMaxTimestamp:[1790820682000|2026-10-01 10:11:22],watermark:[1790820672000|2026-10-01 10:11:12]
```
为了查看方便，我们把输出内容汇总到表格中


| Key | EventTime | CurrentMaxTimeStamp | Watermark |
|---|---|---|:--|
| 0001 | 1790820682000 | 1790820682000 | 1790820672000 |
|  | 2026-10-01 10:11:22 | 2026-10-01 10:11:22 | 2026-10-01 10:11:12 |

此时，Wartermark 的时间，已经落后于 currentMaxTimestamp10 秒了，我们继续输入。
```sh
[root@bigdata04 soft]# nc -l 9000
0001,1790820686000
```
此时，输出内容如下:
```sh
key:0001,eventtime:[1790820686000|2026-10-01 10:11:26],currentMaxTimestamp:[1790820686000|2026-10-01 10:11:26],watermark:[1790820676000|2026-10-01 10:11:16]
```

汇总结果如下:
| Key | EventTime | CurrentMaxTimeStamp | Watermark |
|---|---|:--|:--|
| 0001 | 1790820682000 | 1790820682000 | 1790820672000 |
|  | 2026-10-01 10:11:22 | 2026-10-01 10:11:22 | 2026-10-01 10:11:12 |
| 0001 | 1790820686000 | 1790820686000 | 1790820676000 |
|  | 2026-10-01 10:11:26  | 2026-10-01 10:11:26  | 2026-10-01 10:11:16 |

继续输入:
```sh
[root@bigdata04 soft]# nc -l 9000
0001,1790820692000
```
输出内容如下:
```sh
key:0001,eventtime:[1790820692000|2026-10-01 10:11:32],currentMaxTimestamp:[1790820692000|2026-10-01 10:11:32],watermark:[1790820682000|2026-10-01 10:11:22]
```

汇总结果如下:
| Key | EventTime | CurrentMaxTimeStamp | Watermark |
|---|---|:--|:--|
| 0001 | 1790820682000 | 1790820682000 | 1790820672000 |
|  | **2026-10-02 10:11:22** | 2026-10-01 10:11:22 | 2026-10-01 10:11:12 |
| 0001 | 1790820686000 | 1790820686000 | 1790820676000 |
|  | 2026-10-01 10:11:26  | 2026-10-01 10:11:26  | 2026-10-01 10:11:16 |
| 0001 | 1790820692000 | 1790820692000 | 1790820676000 |
|  | 2026-10-01 10:11:32  | 2026-10-01 10:11:32  | **2026-10-01 10:11:22** |

到这里，`Window` 仍然没有被触发，此时 Watermark 的时间已经等于第一条数据的 `EventTime`了。那么 `Window` 到底什么时候被触发呢？我们再次输入。

```sh
[root@bigdata04 soft]# nc -l 9000
0001,1790820693000
```
输出内容如下：
```sh
key:0001,eventtime:[1790820693000|2026-10-01 10:11:33],currentMaxTimestamp:[1790820693000|2026-10-01 10:11:33],watermark:[1790820683000|2026-10-01 10:11:23]
```

汇总结果如下:
| Key | EventTime | CurrentMaxTimeStamp | Watermark |
|---|---|:--|:--|
| 0001 | 1790820682000 | 1790820682000 | 1790820672000 |
|  | **2026-10-02 10:11:22** | 2026-10-01 10:11:22 | 2026-10-01 10:11:12 |
| 0001 | 1790820686000 | 1790820686000 | 1790820676000 |
|  | 2026-10-01 10:11:26  | 2026-10-01 10:11:26  | 2026-10-01 10:11:16 |
| 0001 | 1790820692000 | 1790820692000 | 1790820676000 |
|  | 2026-10-01 10:11:32  | 2026-10-01 10:11:32  | 2026-10-01 10:11:22 |
| 0001 | 1790820693000 | 1790820693000 | 1790820683000 |
|  | 2026-10-01 10:11:33  | 2026-10-01 10:11:33  | **2026-10-01 10:11:23** |

`Window` 仍然没有触发，此时，我们的数据已经发到 `2026-10-01 10:11:33` 了，根据 `EventTime`来算，最早的数据已经过去了 11s 了，`Window` 还没有开始计算，那到底什么时候会触发`Window` 呢？

我们再次增加 1s，输入:
```sh
[root@bigdata04 soft]# nc -l 9000
0001,1790820694000
```
输出内容如下：
注意：此时窗口执行了
```sh
key:0001,eventtime:[1790820694000|2026-10-01
10:11:34],currentMaxTimestamp:[1790820694000|2026-10-01
10:11:34],watermark:[1790820684000|2026-10-01 10:11:24]
(0001),1,2026-10-01 10:11:22,2026-10-01 10:11:22,2026-10-01 10:11:21,2026-10-01 10:11:24
```
汇总结果如下：
| Key | EventTime | CurrentMaxTimeStamp | Watermark | window_start_time| window_end_time |
|---|---|:--|:--| -- | -- |
| 0001 | 1790820682000 | 1790820682000 | 1790820672000 | | |
|  | **2026-10-02 10:11:22** | 2026-10-01 10:11:22 | 2026-10-01 10:11:12 | | |
| 0001 | 1790820686000 | 1790820686000 | 1790820676000 | | |
|  | 2026-10-01 10:11:26  | 2026-10-01 10:11:26  | 2026-10-01 10:11:16 | | |
| 0001 | 1790820692000 | 1790820692000 | 1790820676000 | | |
|  | 2026-10-01 10:11:32  | 2026-10-01 10:11:32  | 2026-10-01 10:11:22 | | |
| 0001 | 1790820693000 | 1790820693000 | 1790820683000 | | |
|  | 2026-10-01 10:11:33  | 2026-10-01 10:11:33  | 2026-10-01 10:11:23 | | |
| 0001 | 1790820694000 | 1790820694000 | 1790820683000 | | |
|  | 2026-10-01 10:11:34  | 2026-10-01 10:11:34  | **2026-10-01 10:11:24** | [10:11:21 | 10:11:24] |

到这里，我们做一个说明。
`Window` 的触发机制，是先按照自然时间将 `Window` 划分，如果 `Window` 大小是 `3s`，那么 `1min`内会把 `Window` 划分为如下的形式(左闭右开的区间)
```sh
[00:00:00,00:00:03)
[00:00:03,00:00:06)
[00:00:06,00:00:09)
[00:00:09,00:00:12)
[00:00:12,00:00:15)
[00:00:15,00:00:18)
[00:00:18,00:00:21)
[00:00:21,00:00:24)
[00:00:24,00:00:27)
[00:00:27,00:00:30)
[00:00:30,00:00:33)
[00:00:33,00:00:36)
[00:00:36,00:00:39)
[00:00:39,00:00:42)
[00:00:42,00:00:45)
[00:00:45,00:00:48)
[00:00:48,00:00:51)
[00:00:51,00:00:54)
[00:00:54,00:00:57)
[00:00:57,00:01:00)
....
```

`Window` 的设定无关数据本身，而是系统定义好了的。
输入的数据，根据自身的 `EventTime`，将数据划分到不同的 `Window` 中，如果 `Window` 中有数据，则当 `Watermark` 时间>=`EventTime` 时，就符合了 `Window` 触发的条件了，最终决定 `Window` 触发，还是由数据本身的 `EventTime` 所属 `Window` 中的 `window_end_time` 决定。
上面的测试中，最后一条数据到达后，其水位线(`watermark`)已经上升至 `10:11:24`，正好是最早的一条记录所在 `Window` 的 `window_end_time`，所以 `Window` 就被触发了。


为了验证 Window 的触发机制，我们继续输入数据。
```sh
[root@bigdata04 soft]# nc -l 9000
0001,1790820696000
```
输出内容如下：
```sh
key:0001,eventtime:[1790820696000|2026-10-01 10:11:36],currentMaxTimestamp:[1790820696000|2026-10-01 10:11:36],watermark:[1790820686000|2026-10-01 10:11:26]
```
汇总结果如下：
| Key | EventTime | CurrentMaxTimeStamp | Watermark | window_start_time| window_end_time |
|---|---|:--|:--| -- | -- |
| 0001 | 1790820682000 | 1790820682000 | 1790820672000 | | |
|  | **2026-10-02 10:11:22** | 2026-10-01 10:11:22 | 2026-10-01 10:11:12 | | |
| 0001 | 1790820686000 | 1790820686000 | 1790820676000 | | |
|  | 2026-10-01 10:11:26  | 2026-10-01 10:11:26  | 2026-10-01 10:11:16 | | |
| 0001 | 1790820692000 | 1790820692000 | 1790820676000 | | |
|  | 2026-10-01 10:11:32  | 2026-10-01 10:11:32  | 2026-10-01 10:11:22 | | |
| 0001 | 1790820693000 | 1790820693000 | 1790820683000 | | |
|  | 2026-10-01 10:11:33  | 2026-10-01 10:11:33  | 2026-10-01 10:11:23 | | |
| 0001 | 1790820694000 | 1790820694000 | 1790820683000 | | |
|  | 2026-10-01 10:11:34  | 2026-10-01 10:11:34  | 2026-10-01 10:11:24 | [10:11:21 | 10:11:24] |
| 0001 | 1790820696000 | 1790820696000 | 1790820683000 | | |
|  | 2026-10-01 10:11:36  | 2026-10-01 10:11:36  | **2026-10-01 10:11:26** | | |

此时，`Watermark` 时间虽然已经等于第二条数据的时间，但是由于其没有达到第二条数据所在 `Window` 的结束时间，所以 `Window` 并没有被触发。那么，第二条数据所在的 `Window` 时间区间如下:
```sh
[00:00:24,00:00:27)
```
也就是说，我们必须输入一个大于 `10:11:37` 的数据，第二条数据所在的 `Window` 才会被触发，我们继续输入:
```sh
[root@bigdata04 soft]# nc -l 9000
0001,1790820697000
```

输出内容如下：
```sh
key:0001,eventtime:[1790820697000|2026-10-01 10:11:37],currentMaxTimestamp:[1790820697000|2026-10-01 10:11:37],watermark:[1790820687000|2026-10-01 10:11:27]
(0001),1,2026-10-01 10:11:26,2026-10-01 10:11:26,2026-10-01 10:11:24,2026-10-01 10:11:27
```

汇总结果如下：
| Key | EventTime | CurrentMaxTimeStamp | Watermark | window_start_time| window_end_time |
|---|---|:--|:--| -- | -- |
| 0001 | 1790820682000 | 1790820682000 | 1790820672000 | | |
|  | **2026-10-02 10:11:22** | 2026-10-01 10:11:22 | 2026-10-01 10:11:12 | | |
| 0001 | 1790820686000 | 1790820686000 | 1790820676000 | | |
|  | 2026-10-01 10:11:26  | 2026-10-01 10:11:26  | 2026-10-01 10:11:16 | | |
| 0001 | 1790820692000 | 1790820692000 | 1790820676000 | | |
|  | 2026-10-01 10:11:32  | 2026-10-01 10:11:32  | 2026-10-01 10:11:22 | | |
| 0001 | 1790820693000 | 1790820693000 | 1790820683000 | | |
|  | 2026-10-01 10:11:33  | 2026-10-01 10:11:33  | 2026-10-01 10:11:23 | | |
| 0001 | 1790820694000 | 1790820694000 | 1790820683000 | | |
|  | 2026-10-01 10:11:34  | 2026-10-01 10:11:34  | 2026-10-01 10:11:24 | [10:11:21 | 10:11:24] |
| 0001 | 1790820696000 | 1790820696000 | 1790820683000 | | |
|  | 2026-10-01 10:11:36  | 2026-10-01 10:11:36  | 2026-10-01 10:11:26 | | |
| 0001 | 1790820697000 | 1790820697000 | 1790820683000 | | |
|  | 2026-10-01 10:11:37  | 2026-10-01 10:11:37  | 2026-10-01 10:11:27 | [10:11:24 | 10:11:27] |


Window 的触发要符合以下几个条件:
- 1：Watermark 时间 >= window_end_time。
- 2：在[window_start_time,window_end_time)区间中有数据存在(注意是左闭右开的区间)。

同时满足了以上 2 个条件，Window 才会触发。

## Watermark+EventTime 处理乱序数据
我们上面的测试，数据都是按照时间顺序递增的，现在，我们输入一些乱序的数据，看看`Watermark` 结合 `EventTime` 机制，是如何处理乱序数据的。
在上面的基础上再输入两行数据。
```sh
[root@hadoop100 soft]# nc -l 9000
0001,1790820699000
0001,1790820691000
```
输出内容如下：
```sh
key:0001,eventtime:[1790820699000|2026-10-01 10:11:39],currentMaxTimestamp:[1790820699000|2026-10-01 10:11:39],watermark:[1790820689000|2026-10-01 10:11:29]
key:0001,eventtime:[1790820691000|2026-10-01 10:11:31],currentMaxTimestamp:[1790820699000|2026-10-01 10:11:39],watermark:[1790820689000|2026-10-01 10:11:29]
```

汇总结果如下：
| Key | EventTime | CurrentMaxTimeStamp | Watermark | window_start_time| window_end_time |
|---|---|:--|:--| -- | -- |
| 0001 | 1790820682000 | 1790820682000 | 1790820672000 | | |
|  | **2026-10-02 10:11:22** | 2026-10-01 10:11:22 | 2026-10-01 10:11:12 | | |
| 0001 | 1790820686000 | 1790820686000 | 1790820676000 | | |
|  | 2026-10-01 10:11:26  | 2026-10-01 10:11:26  | 2026-10-01 10:11:16 | | |
| 0001 | 1790820692000 | 1790820692000 | 1790820676000 | | |
|  | 2026-10-01 10:11:32  | 2026-10-01 10:11:32  | 2026-10-01 10:11:22 | | |
| 0001 | 1790820693000 | 1790820693000 | 1790820683000 | | |
|  | 2026-10-01 10:11:33  | 2026-10-01 10:11:33  | 2026-10-01 10:11:23 | | |
| 0001 | 1790820694000 | 1790820694000 | 1790820683000 | | |
|  | 2026-10-01 10:11:34  | 2026-10-01 10:11:34  | 2026-10-01 10:11:24 | [10:11:21 | 10:11:24] |
| 0001 | 1790820696000 | 1790820696000 | 1790820683000 | | |
|  | 2026-10-01 10:11:36  | 2026-10-01 10:11:36  | 2026-10-01 10:11:26 | | |
| 0001 | 1790820697000 | 1790820697000 | 1790820683000 | | |
|  | 2026-10-01 10:11:37  | 2026-10-01 10:11:37  | 2026-10-01 10:11:27 | [10:11:24 | 10:11:27] |
| 0001 | 1790820699000 | 1790820699000 | 1790820689000 | | |
|  | 2026-10-01 10:11:39  | 2026-10-01 10:11:39  | 2026-10-01 10:11:29 | | |
| 0001 | 1790820691000 | 1790820699000 | 1790820689000 | | |
|  | 2026-10-01 10:11:31  | **2026-10-01 10:11:39**  | **2026-10-01 10:11:29** | | |

可以看到，虽然我们输入了一个 `10:11:31` 的数据，但是 `currentMaxTimestamp` 和 `Watermark` 都没变。此时，按照我们上面提到的公式。
- 1：`watermark` 时间 >= `window_end_time`
- 2：在[`window_start_time`,`window_end_time`)中有数据存在

`Watermark` 时间（10:11:29） < `window_end_time`（10:11:33），因此不能触发 `Window`

那如果我们再次输入一条 10:11:43 的数据，此时 `Watermark` 时间会上升到 10:11:33，这时的 `Window` 一定就会触发了，我们试一试 ，继续输入内容。

```sh
[root@hadoop100 soft]# nc -l 9000
0001,1790820703000
```

输出内容:
```sh
key:0001,eventtime:[1790820703000|2026-10-01 10:11:43],currentMaxTimestamp:[1790820703000|2026-10-01 10:11:43],watermark:[1790820693000|2026-10-01 10:11:33]
(0001),2,2026-10-01 10:11:31,2026-10-01 10:11:32,2026-10-01 10:11:30,2026-10-01 10:11:33
```

汇总结果如下：
| Key | EventTime | CurrentMaxTimeStamp | Watermark | window_start_time| window_end_time |
|---|---|:--|:--| -- | -- |
| 0001 | 1790820682000 | 1790820682000 | 1790820672000 | | |
|  | **2026-10-02 10:11:22** | 2026-10-01 10:11:22 | 2026-10-01 10:11:12 | | |
| 0001 | 1790820686000 | 1790820686000 | 1790820676000 | | |
|  | 2026-10-01 10:11:26  | 2026-10-01 10:11:26  | 2026-10-01 10:11:16 | | |
| 0001 | 1790820692000 | 1790820692000 | 1790820676000 | | |
|  | 2026-10-01 10:11:32  | 2026-10-01 10:11:32  | 2026-10-01 10:11:22 | | |
| 0001 | 1790820693000 | 1790820693000 | 1790820683000 | | |
|  | 2026-10-01 10:11:33  | 2026-10-01 10:11:33  | 2026-10-01 10:11:23 | | |
| 0001 | 1790820694000 | 1790820694000 | 1790820683000 | | |
|  | 2026-10-01 10:11:34  | 2026-10-01 10:11:34  | 2026-10-01 10:11:24 | [10:11:21 | 10:11:24] |
| 0001 | 1790820696000 | 1790820696000 | 1790820683000 | | |
|  | 2026-10-01 10:11:36  | 2026-10-01 10:11:36  | 2026-10-01 10:11:26 | | |
| 0001 | 1790820697000 | 1790820697000 | 1790820683000 | | |
|  | 2026-10-01 10:11:37  | 2026-10-01 10:11:37  | 2026-10-01 10:11:27 | [10:11:24 | 10:11:27] |
| 0001 | 1790820699000 | 1790820699000 | 1790820689000 | | |
|  | 2026-10-01 10:11:39  | 2026-10-01 10:11:39  | 2026-10-01 10:11:29 | | |
| 0001 | 1790820691000 | 1790820699000 | 1790820689000 | | |
|  | 2026-10-01 10:11:31  | 2026-10-01 10:11:39  | 2026-10-01 10:11:29 | | |
| 0001 | 1790820703000 | 1790820703000 | 1790820693000 | | |
|  | 2026-10-01 10:11:43  | 2026-10-01 10:11:43  | 2026-10-01 10:11:33 | [10:11:30 | 10:11:33] |

这里我们可以看到，窗口中有 2 个数据，10:11:31 和 10:11:32，但是没有 10:11:33 的数据，原因是窗口是一个前闭后开的区间，10:11:33 的数据是属于[10:11:33,10:11:36)这个窗口的。
上边的结果，已经表明，对于迟到的数据，Flink 可以通过 Watermark 来实现处理一定范围内的乱序数据。那么对于“迟到(late element)”太久的数据，Flink 是怎么处理的呢？