# HDFSApi

## 1.命令系统
```shell
hdfs dfs -ls /
hdfs dfs -put anaconda-ks.cfg /
hdfs dfs -cat /anaconda-ks.cfg
hdfs dfs -get /anaconda-ks.cfg ./anaconda #下载文件到本地
hdfs dfs -mkdir -p /application/hadoop
hdfs dfs -rm -r /application
```
```
[root@CentOS-01 ~]# hdfs dfs
Usage: hadoop fs [generic options]
        [-appendToFile <localsrc> ... <dst>]
        [-cat [-ignoreCrc] <src> ...]
        [-checksum <src> ...]
        [-chgrp [-R] GROUP PATH...]
        [-chmod [-R] <MODE[,MODE]... | OCTALMODE> PATH...]
        [-chown [-R] [OWNER][:[GROUP]] PATH...]
        [-copyFromLocal [-f] [-p] [-l] [-d] [-t <thread count>] <localsrc> ... <dst>]
        [-copyToLocal [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
        [-count [-q] [-h] [-v] [-t [<storage type>]] [-u] [-x] [-e] <path> ...]
        [-cp [-f] [-p | -p[topax]] [-d] <src> ... <dst>]
        [-createSnapshot <snapshotDir> [<snapshotName>]]
        [-deleteSnapshot <snapshotDir> <snapshotName>]
        [-df [-h] [<path> ...]]
        [-du [-s] [-h] [-v] [-x] <path> ...]
        [-expunge]
        [-find <path> ... <expression> ...]
        [-get [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
        [-getfacl [-R] <path>]
        [-getfattr [-R] {-n name | -d} [-e en] <path>]
        [-getmerge [-nl] [-skip-empty-file] <src> <localdst>]
        [-head <file>]
        [-help [cmd ...]]
        [-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [<path> ...]]
        [-mkdir [-p] <path> ...]
        [-moveFromLocal <localsrc> ... <dst>]
        [-moveToLocal <src> <localdst>]
        [-mv <src> ... <dst>]
        [-put [-f] [-p] [-l] [-d] <localsrc> ... <dst>]
        [-renameSnapshot <snapshotDir> <oldName> <newName>]
        [-rm [-f] [-r|-R] [-skipTrash] [-safely] <src> ...]
        [-rmdir [--ignore-fail-on-non-empty] <dir> ...]
        [-setfacl [-R] [{-b|-k} {-m|-x <acl_spec>} <path>]|[--set <acl_spec> <path>]]
        [-setfattr {-n name [-v value] | -x name} <path>]
        [-setrep [-R] [-w] <rep> <path> ...]
        [-stat [format] <path> ...]
        [-tail [-f] <file>]
        [-test -[defsz] <path>]
        [-text [-ignoreCrc] <src> ...]
        [-touch [-a] [-m] [-t TIMESTAMP ] [-c] <path> ...]
        [-touchz <path> ...]
        [-truncate [-w] <length> <path> ...]
        [-usage [cmd ...]]
```

## 02.javaApi
```
<dependency>
    <groupId>org.apache.hadoop</groupId>
    <artifactId>hadoop-client</artifactId>
    <version>3.2.0</version>
</dependency>
```
```java
package com.amos.simple2.service;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.BlockLocation;
import org.apache.hadoop.fs.FSDataInputStream;
import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.FileStatus;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IOUtils;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.Test;

import java.io.IOException;
import java.net.URI;
import java.net.URISyntaxException;

/**
 * @program: simple2
 * @description:
 * @author: wangyuqing3
 * @created: 2020/12/26 19:55
 */
public class HDFSAppTest {
    private static final String HDFS_PATH = "hdfs://10.211.55.5:8020";
    private FileSystem fileSystem;
    Configuration configuration;

    @BeforeEach
    public void setUp() throws URISyntaxException, IOException, InterruptedException {
        configuration = new Configuration();
        this.configuration = configuration;
        this.fileSystem = FileSystem.get(new URI(HDFS_PATH), configuration, "hadoop");
    }

    /**
     * 读取文件
     *
     * @throws IOException
     */
    @Test
    public void cat() throws IOException {
        final FSDataInputStream in = fileSystem.open(new Path("/pyspark"));
        IOUtils.copyBytes(in, System.out, 1024);
    }

    /**
     * 写入文件
     *
     * @throws IOException
     */
    @Test
    public void create() throws IOException {
        final FSDataOutputStream out = fileSystem.create(new Path("/a.txt"));
        out.writeUTF("hello pk");
        out.close();
    }

    /**
     * 重命名文件
     *
     * @throws IOException
     */
    @Test
    public void rename() throws IOException {
        final boolean status = fileSystem.rename(new Path("/a.txt"), new Path("b.txt"));
        System.out.println(status);
    }

    /**
     * 从本地拷贝文件
     *
     * @throws IOException
     */
    @Test
    public void copyFromLocalFile() throws IOException {
        fileSystem.copyFromLocalFile(new Path("./b.txt"), new Path("/c.txt"));
    }

    /**
     * 下载文件
     */
    @Test
    public void copyToLocalFile() throws IOException {
        fileSystem.copyToLocalFile(new Path("/a.txt"), new Path("./"));
    }

    /**
     * 查看目录
     *
     * @throws IOException
     */
    @Test
    public void listFiles() throws IOException {
        final FileStatus[] files = fileSystem.listStatus(new Path("/"));
        for (FileStatus fileStatus : files) {
            System.out.println(fileStatus.getPath());
        }
    }

    /**
     * 查看块信息
     * @throws IOException
     */
    @Test
    public void getFileBlockLocations() throws IOException {
        final FileStatus fileStatus = fileSystem.getFileStatus(new Path("/a.txt"));
        final BlockLocation[] fileBlocks = fileSystem.getFileBlockLocations(fileStatus, 0, fileStatus.getLen());
        for (BlockLocation block : fileBlocks) {
            for (String name : block.getNames()) {
                System.out.println(name + ":" + block.getOffset() + ":" + block.getLength());
            }
        }
    }

    /**
     * 删除文件
     */
    public void delete() throws IOException {
        final boolean status = fileSystem.delete(new Path("/a.txt"),true);
    }
}
```